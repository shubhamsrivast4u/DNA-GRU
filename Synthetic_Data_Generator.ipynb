{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "415631c5-4e3f-4782-a08c-41df3b3f302c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      " ALL DATASET CONFIGURATIONS\n",
      "====================================================================================================\n",
      "Dataset                   Label   Dev   Idx   Sequencing           Synthesis            Method\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Erlich                    152     10    16    Ilumina miSeq        Twist Bioscience     set_EZ17_values\n",
      "Grass                     117     11    13    Ilumina miSeq        CustomArray          set_G15_values\n",
      "Organick                  110     5     33    Ilumina NextSeq      Twist Bioscience     set_O17_values\n",
      "Srinivasavaradhan         110     5     4     MinION               Twist Bioscience     set_R21_values\n",
      "DNAformer_Illumina_Full   140     4     12    Ilumina miSeq-0922   Twist Bioscience-0922 set_BOS22_values\n",
      "DNAformer_Illumina_Pilot  140     4     12    Ilumina miSeq        Twist Bioscience     set_EZ17_values\n",
      "DNAformer_Nanopore_Pilot  140     10    12    MinIONShort          Twist Bioscience     set_B22_values\n",
      "DNAformer_Nanopore_Full   140     4     12    Nanopore_pilot_v2_multi Twist Bioscience_nanopore_pilot_v2_multi set_BOS22PILOTOMER_values_multi\n",
      "====================================================================================================\n",
      "\n",
      "======================================================================\n",
      " DNAformer Synthetic Data Generator - ALL CONFIGURATIONS\n",
      "======================================================================\n",
      "\n",
      "Will generate 1,500,000 clusters for each of:\n",
      "  - Erlich: Erlich et al. (2017) - DNA Fountain, Twist + Illumina miSeq\n",
      "  - Grass: Grass et al. (2015) - CustomArray + Illumina miSeq\n",
      "  - Organick: Organick et al. (2018) - Twist + Illumina NextSeq\n",
      "  - Srinivasavaradhan: Srinivasavaradhan et al. (Pfitser) - Twist + MinION\n",
      "  - DNAformer_Illumina_Full: DNAformer Full Illumina (2022) - Twist + miSeq\n",
      "  - DNAformer_Illumina_Pilot: DNAformer Pilot Illumina - Twist + miSeq\n",
      "  - DNAformer_Nanopore_Pilot: DNAformer Pilot Nanopore - Twist + MinION Short\n",
      "  - DNAformer_Nanopore_Full: DNAformer Full Nanopore - Twist + MinION (with multipliers)\n",
      "\n",
      "Output directory: generated_data_corrected\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      "GENERATING: Erlich\n",
      "======================================================================\n",
      "Description: Erlich et al. (2017) - DNA Fountain, Twist + Illumina miSeq\n",
      "\n",
      "Dataset Parameters:\n",
      "  Label length:     152 bp\n",
      "  Max deviation:    10 bp\n",
      "  Max read length:  162 bp\n",
      "  Index length:     16 bp\n",
      "  Sequencing:       Ilumina miSeq\n",
      "  Synthesis:        Twist Bioscience\n",
      "  Error rates:      set_EZ17_values()\n",
      "\n",
      "Augmentation Settings:\n",
      "  Noise deviation (δ): 0.1 (enabled)\n",
      "  False copies:        enabled (30% prob, max 2)\n",
      "  Cluster size:        1-16\n",
      "\n",
      "Output: generated_data_corrected/binned_synthetic_erlich.txt\n",
      "Clusters to generate: 1,500,000\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Erlich: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500000/1500000 [1:19:42<00:00, 313.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully generated 1,500,000 clusters for Erlich\n",
      "   Saved to: generated_data_corrected/binned_synthetic_erlich.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING: Grass\n",
      "======================================================================\n",
      "Description: Grass et al. (2015) - CustomArray + Illumina miSeq\n",
      "\n",
      "Dataset Parameters:\n",
      "  Label length:     117 bp\n",
      "  Max deviation:    11 bp\n",
      "  Max read length:  128 bp\n",
      "  Index length:     13 bp\n",
      "  Sequencing:       Ilumina miSeq\n",
      "  Synthesis:        CustomArray\n",
      "  Error rates:      set_G15_values()\n",
      "\n",
      "Augmentation Settings:\n",
      "  Noise deviation (δ): 0.1 (enabled)\n",
      "  False copies:        enabled (30% prob, max 2)\n",
      "  Cluster size:        1-16\n",
      "\n",
      "Output: generated_data_corrected/binned_synthetic_grass.txt\n",
      "Clusters to generate: 1,500,000\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Grass: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500000/1500000 [1:04:11<00:00, 389.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully generated 1,500,000 clusters for Grass\n",
      "   Saved to: generated_data_corrected/binned_synthetic_grass.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING: Organick\n",
      "======================================================================\n",
      "Description: Organick et al. (2018) - Twist + Illumina NextSeq\n",
      "\n",
      "Dataset Parameters:\n",
      "  Label length:     110 bp\n",
      "  Max deviation:    5 bp\n",
      "  Max read length:  115 bp\n",
      "  Index length:     33 bp\n",
      "  Sequencing:       Ilumina NextSeq\n",
      "  Synthesis:        Twist Bioscience\n",
      "  Error rates:      set_O17_values()\n",
      "\n",
      "Augmentation Settings:\n",
      "  Noise deviation (δ): 0.1 (enabled)\n",
      "  False copies:        enabled (30% prob, max 2)\n",
      "  Cluster size:        1-16\n",
      "\n",
      "Output: generated_data_corrected/binned_synthetic_organick.txt\n",
      "Clusters to generate: 1,500,000\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Organick: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500000/1500000 [58:00<00:00, 430.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully generated 1,500,000 clusters for Organick\n",
      "   Saved to: generated_data_corrected/binned_synthetic_organick.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING: Srinivasavaradhan\n",
      "======================================================================\n",
      "Description: Srinivasavaradhan et al. (Pfitser) - Twist + MinION\n",
      "\n",
      "Dataset Parameters:\n",
      "  Label length:     110 bp\n",
      "  Max deviation:    5 bp\n",
      "  Max read length:  115 bp\n",
      "  Index length:     4 bp\n",
      "  Sequencing:       MinION\n",
      "  Synthesis:        Twist Bioscience\n",
      "  Error rates:      set_R21_values()\n",
      "\n",
      "Augmentation Settings:\n",
      "  Noise deviation (δ): 0.1 (enabled)\n",
      "  False copies:        enabled (30% prob, max 2)\n",
      "  Cluster size:        1-16\n",
      "\n",
      "Output: generated_data_corrected/binned_synthetic_srinivasavaradhan.txt\n",
      "Clusters to generate: 1,500,000\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Srinivasavaradhan: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500000/1500000 [1:09:28<00:00, 359.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully generated 1,500,000 clusters for Srinivasavaradhan\n",
      "   Saved to: generated_data_corrected/binned_synthetic_srinivasavaradhan.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING: DNAformer_Illumina_Full\n",
      "======================================================================\n",
      "Description: DNAformer Full Illumina (2022) - Twist + miSeq\n",
      "\n",
      "Dataset Parameters:\n",
      "  Label length:     140 bp\n",
      "  Max deviation:    4 bp\n",
      "  Max read length:  144 bp\n",
      "  Index length:     12 bp\n",
      "  Sequencing:       Ilumina miSeq-0922\n",
      "  Synthesis:        Twist Bioscience-0922\n",
      "  Error rates:      set_BOS22_values()\n",
      "\n",
      "Augmentation Settings:\n",
      "  Noise deviation (δ): 0.1 (enabled)\n",
      "  False copies:        enabled (30% prob, max 2)\n",
      "  Cluster size:        1-16\n",
      "\n",
      "Output: generated_data_corrected/binned_synthetic_dnaformer_illumina_full.txt\n",
      "Clusters to generate: 1,500,000\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating DNAformer_Illumina_Full: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500000/1500000 [1:11:02<00:00, 351.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully generated 1,500,000 clusters for DNAformer_Illumina_Full\n",
      "   Saved to: generated_data_corrected/binned_synthetic_dnaformer_illumina_full.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING: DNAformer_Illumina_Pilot\n",
      "======================================================================\n",
      "Description: DNAformer Pilot Illumina - Twist + miSeq\n",
      "\n",
      "Dataset Parameters:\n",
      "  Label length:     140 bp\n",
      "  Max deviation:    4 bp\n",
      "  Max read length:  144 bp\n",
      "  Index length:     12 bp\n",
      "  Sequencing:       Ilumina miSeq\n",
      "  Synthesis:        Twist Bioscience\n",
      "  Error rates:      set_EZ17_values()\n",
      "\n",
      "Augmentation Settings:\n",
      "  Noise deviation (δ): 0.1 (enabled)\n",
      "  False copies:        enabled (30% prob, max 2)\n",
      "  Cluster size:        1-16\n",
      "\n",
      "Output: generated_data_corrected/binned_synthetic_dnaformer_illumina_pilot.txt\n",
      "Clusters to generate: 1,500,000\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating DNAformer_Illumina_Pilot: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500000/1500000 [1:12:18<00:00, 345.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully generated 1,500,000 clusters for DNAformer_Illumina_Pilot\n",
      "   Saved to: generated_data_corrected/binned_synthetic_dnaformer_illumina_pilot.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING: DNAformer_Nanopore_Pilot\n",
      "======================================================================\n",
      "Description: DNAformer Pilot Nanopore - Twist + MinION Short\n",
      "\n",
      "Dataset Parameters:\n",
      "  Label length:     140 bp\n",
      "  Max deviation:    10 bp\n",
      "  Max read length:  150 bp\n",
      "  Index length:     12 bp\n",
      "  Sequencing:       MinIONShort\n",
      "  Synthesis:        Twist Bioscience\n",
      "  Error rates:      set_B22_values()\n",
      "\n",
      "Augmentation Settings:\n",
      "  Noise deviation (δ): 0.1 (enabled)\n",
      "  False copies:        enabled (30% prob, max 2)\n",
      "  Cluster size:        1-16\n",
      "\n",
      "Output: generated_data_corrected/binned_synthetic_dnaformer_nanopore_pilot.txt\n",
      "Clusters to generate: 1,500,000\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating DNAformer_Nanopore_Pilot: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500000/1500000 [1:23:23<00:00, 299.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully generated 1,500,000 clusters for DNAformer_Nanopore_Pilot\n",
      "   Saved to: generated_data_corrected/binned_synthetic_dnaformer_nanopore_pilot.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      "GENERATING: DNAformer_Nanopore_Full\n",
      "======================================================================\n",
      "Description: DNAformer Full Nanopore - Twist + MinION (with multipliers)\n",
      "\n",
      "Dataset Parameters:\n",
      "  Label length:     140 bp\n",
      "  Max deviation:    4 bp\n",
      "  Max read length:  144 bp\n",
      "  Index length:     12 bp\n",
      "  Sequencing:       Nanopore_pilot_v2_multi\n",
      "  Synthesis:        Twist Bioscience_nanopore_pilot_v2_multi\n",
      "  Error rates:      set_BOS22PILOTOMER_values_multi()\n",
      "\n",
      "Augmentation Settings:\n",
      "  Noise deviation (δ): 0.1 (enabled)\n",
      "  False copies:        enabled (30% prob, max 2)\n",
      "  Cluster size:        1-16\n",
      "\n",
      "Output: generated_data_corrected/binned_synthetic_dnaformer_nanopore_full.txt\n",
      "Clusters to generate: 1,500,000\n",
      "======================================================================\n",
      "  Applied noise coefficients: {'del_mult': 1.25, 'ins_mult': 1.25, 'sub_mult': 1.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating DNAformer_Nanopore_Full: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1500000/1500000 [1:29:19<00:00, 279.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Successfully generated 1,500,000 clusters for DNAformer_Nanopore_Full\n",
      "   Saved to: generated_data_corrected/binned_synthetic_dnaformer_nanopore_full.txt\n",
      "\n",
      "\n",
      "======================================================================\n",
      " GENERATION COMPLETE - SUMMARY\n",
      "======================================================================\n",
      "  ✅ Erlich: generated_data_corrected/binned_synthetic_erlich.txt\n",
      "  ✅ Grass: generated_data_corrected/binned_synthetic_grass.txt\n",
      "  ✅ Organick: generated_data_corrected/binned_synthetic_organick.txt\n",
      "  ✅ Srinivasavaradhan: generated_data_corrected/binned_synthetic_srinivasavaradhan.txt\n",
      "  ✅ DNAformer_Illumina_Full: generated_data_corrected/binned_synthetic_dnaformer_illumina_full.txt\n",
      "  ✅ DNAformer_Illumina_Pilot: generated_data_corrected/binned_synthetic_dnaformer_illumina_pilot.txt\n",
      "  ✅ DNAformer_Nanopore_Pilot: generated_data_corrected/binned_synthetic_dnaformer_nanopore_pilot.txt\n",
      "  ✅ DNAformer_Nanopore_Full: generated_data_corrected/binned_synthetic_dnaformer_nanopore_full.txt\n",
      "======================================================================\n",
      "\n",
      "======================================================================\n",
      " NEXT STEPS\n",
      "======================================================================\n",
      "\n",
      "To use the generated data for training, update your training config:\n",
      "\n",
      "For Erlich dataset:\n",
      "    TRAIN_FILE = \"generated_data_corrected/binned_synthetic_erlich.txt\"\n",
      "    LABEL_SEQ_LEN = 152\n",
      "    MAX_READ_LEN = 162  # label_length + max_deviation\n",
      "\n",
      "For Grass dataset:\n",
      "    TRAIN_FILE = \"generated_data_corrected/binned_synthetic_grass.txt\"\n",
      "    LABEL_SEQ_LEN = 117\n",
      "    MAX_READ_LEN = 128  # 117 + 11\n",
      "\n",
      "For Organick dataset:\n",
      "    TRAIN_FILE = \"generated_data_corrected/binned_synthetic_organick.txt\"\n",
      "    LABEL_SEQ_LEN = 110\n",
      "    MAX_READ_LEN = 115  # 110 + 5\n",
      "\n",
      "For DNAformer Nanopore:\n",
      "    TRAIN_FILE = \"generated_data_corrected/binned_synthetic_dnaformer_nanopore_full.txt\"\n",
      "    LABEL_SEQ_LEN = 140\n",
      "    MAX_READ_LEN = 144  # 140 + 4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\"\"\"\n",
    "============================================================================\n",
    "CORRECTED DNAformer Synthetic Data Generator - ALL CONFIGURATIONS\n",
    "============================================================================\n",
    "\n",
    "Based on: \"Scalable and robust DNA-based storage via coding theory and deep learning\"\n",
    "Nature Machine Intelligence, 2025\n",
    "\n",
    "This script generates synthetic data for ALL dataset configurations mentioned\n",
    "in the DNAformer paper and GitHub code.\n",
    "\n",
    "Dataset configurations extracted from:\n",
    "- train.py config class comments\n",
    "- error_rates_setup.py set_values() function\n",
    "- Supplementary materials\n",
    "\n",
    "Author: Corrected based on DNAformer paper and GitHub implementation\n",
    "============================================================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import random\n",
    "import copy\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "\n",
    "# Import from your existing DataGenerator package\n",
    "from DataGenerator.error_rates_setup import ErrorRates\n",
    "from DataGenerator.cluster_generator import ClusterGenerator\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# ALL DATASET CONFIGURATIONS (from train.py and error_rates_setup.py)\n",
    "# ============================================================================\n",
    "\n",
    "DATASET_CONFIGS = {\n",
    "    # =========================================================================\n",
    "    # PUBLIC BENCHMARK DATASETS (Open source datasets from train.py comments)\n",
    "    # =========================================================================\n",
    "    \n",
    "    \"Erlich\": {\n",
    "        # From train.py: Erlich: cluster: 72,000 label: 152 dev: 10 index: 16 \n",
    "        #                sequencing: Ilumina miSeq synthesis: Twist Bioscience\n",
    "        \"label_length\": 152,\n",
    "        \"max_deviation\": 10,\n",
    "        \"index_length\": 16,\n",
    "        \"sequencing_tech\": \"Ilumina miSeq\",\n",
    "        \"synthesis_tech\": \"Twist Bioscience\",\n",
    "        \"error_rates_method\": \"set_EZ17_values\",\n",
    "        \"uses_noise_coef\": False,\n",
    "        \"description\": \"Erlich et al. (2017) - DNA Fountain, Twist + Illumina miSeq\",\n",
    "        \"real_cluster_count\": 72000\n",
    "    },\n",
    "    \n",
    "    \"Grass\": {\n",
    "        # From train.py: Grass: cluster: 4989 label: 117 dev: 11 index: 13\n",
    "        #                sequencing: Ilumina miSeq synthesis: CustomArray\n",
    "        \"label_length\": 117,\n",
    "        \"max_deviation\": 11,\n",
    "        \"index_length\": 13,\n",
    "        \"sequencing_tech\": \"Ilumina miSeq\",\n",
    "        \"synthesis_tech\": \"CustomArray\",\n",
    "        \"error_rates_method\": \"set_G15_values\",\n",
    "        \"uses_noise_coef\": False,\n",
    "        \"description\": \"Grass et al. (2015) - CustomArray + Illumina miSeq\",\n",
    "        \"real_cluster_count\": 4989\n",
    "    },\n",
    "    \n",
    "    \"Organick\": {\n",
    "        # From train.py: Luis: cluster: 596,499 label: 110 dev: 5 index: 33\n",
    "        #                sequencing: Ilumina NextSeq synthesis: Twist Bioscience\n",
    "        \"label_length\": 110,\n",
    "        \"max_deviation\": 5,\n",
    "        \"index_length\": 33,\n",
    "        \"sequencing_tech\": \"Ilumina NextSeq\",\n",
    "        \"synthesis_tech\": \"Twist Bioscience\",\n",
    "        \"error_rates_method\": \"set_O17_values\",\n",
    "        \"uses_noise_coef\": False,\n",
    "        \"description\": \"Organick et al. (2018) - Twist + Illumina NextSeq\",\n",
    "        \"real_cluster_count\": 596499\n",
    "    },\n",
    "    \n",
    "    \"Srinivasavaradhan\": {\n",
    "        # From train.py: Pfitser: cluster: 9984 label: 110 dev: 5 index: 4\n",
    "        #                sequencing: MinION synthesis: Twist Bioscience\n",
    "        \"label_length\": 110,\n",
    "        \"max_deviation\": 5,\n",
    "        \"index_length\": 4,\n",
    "        \"sequencing_tech\": \"MinION\",\n",
    "        \"synthesis_tech\": \"Twist Bioscience\",\n",
    "        \"error_rates_method\": \"set_R21_values\",\n",
    "        \"uses_noise_coef\": False,\n",
    "        \"description\": \"Srinivasavaradhan et al. (Pfitser) - Twist + MinION\",\n",
    "        \"real_cluster_count\": 9984\n",
    "    },\n",
    "    \n",
    "    # =========================================================================\n",
    "    # DNAformer's OWN DATASETS (Their pilot and full datasets)\n",
    "    # =========================================================================\n",
    "    \n",
    "    \"DNAformer_Illumina_Full\": {\n",
    "        # From train.py: full_illumina cluster: 109,944 label: 128 dev: 4 index: 12\n",
    "        #                sequencing: Ilumina miSeq-0922 synthesis: Twist Bioscience-0922\n",
    "        \"label_length\": 140,  # 128 after removing 12-bp index, but we generate full 140\n",
    "        \"max_deviation\": 4,\n",
    "        \"index_length\": 12,\n",
    "        \"sequencing_tech\": \"Ilumina miSeq-0922\",\n",
    "        \"synthesis_tech\": \"Twist Bioscience-0922\",\n",
    "        \"error_rates_method\": \"set_BOS22_values\",\n",
    "        \"uses_noise_coef\": False,\n",
    "        \"description\": \"DNAformer Full Illumina (2022) - Twist + miSeq\",\n",
    "        \"real_cluster_count\": 109944\n",
    "    },\n",
    "    \n",
    "    \"DNAformer_Illumina_Pilot\": {\n",
    "        # From train.py: pilot_illumina: cluster: 1,000 label: 128 dev: 4 index: 12\n",
    "        #                sequencing: Ilumina miSeq synthesis: Twist Bioscience\n",
    "        \"label_length\": 140,\n",
    "        \"max_deviation\": 4,\n",
    "        \"index_length\": 12,\n",
    "        \"sequencing_tech\": \"Ilumina miSeq\",\n",
    "        \"synthesis_tech\": \"Twist Bioscience\",\n",
    "        \"error_rates_method\": \"set_EZ17_values\",  # Uses EZ17 for pilot\n",
    "        \"uses_noise_coef\": False,\n",
    "        \"description\": \"DNAformer Pilot Illumina - Twist + miSeq\",\n",
    "        \"real_cluster_count\": 1000\n",
    "    },\n",
    "    \n",
    "    \"DNAformer_Nanopore_Pilot\": {\n",
    "        # From train.py: pilot_nanopore: cluster: 1,000 label: 128 dev: 10 index: 12\n",
    "        #                sequencing: MinIONShort synthesis: Twist Bioscience\n",
    "        \"label_length\": 140,\n",
    "        \"max_deviation\": 10,\n",
    "        \"index_length\": 12,\n",
    "        \"sequencing_tech\": \"MinIONShort\",\n",
    "        \"synthesis_tech\": \"Twist Bioscience\",\n",
    "        \"error_rates_method\": \"set_B22_values\",\n",
    "        \"uses_noise_coef\": False,\n",
    "        \"description\": \"DNAformer Pilot Nanopore - Twist + MinION Short\",\n",
    "        \"real_cluster_count\": 1000\n",
    "    },\n",
    "    \n",
    "    \"DNAformer_Nanopore_Full\": {\n",
    "        # From train.py: full_nanopore cluster: 109,944 label: 128 dev: 4 index: 12\n",
    "        # Uses Nanopore_pilot_v2_multi with noise coefficients\n",
    "        \"label_length\": 140,\n",
    "        \"max_deviation\": 4,\n",
    "        \"index_length\": 12,\n",
    "        \"sequencing_tech\": \"Nanopore_pilot_v2_multi\",\n",
    "        \"synthesis_tech\": \"Twist Bioscience_nanopore_pilot_v2_multi\",\n",
    "        \"error_rates_method\": \"set_BOS22PILOTOMER_values_multi\",\n",
    "        \"uses_noise_coef\": True,\n",
    "        \"noise_coef\": {'del_mult': 1.25, 'ins_mult': 1.25, 'sub_mult': 1.25},\n",
    "        \"description\": \"DNAformer Full Nanopore - Twist + MinION (with multipliers)\",\n",
    "        \"real_cluster_count\": 109944\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# AUGMENTATION CONFIGURATION (from train.py config class)\n",
    "# ============================================================================\n",
    "\n",
    "class AugmentationConfig:\n",
    "    \"\"\"\n",
    "    Data augmentation parameters from the DNAformer paper.\n",
    "    \n",
    "    From train.py:\n",
    "        generate_data_noise    = 0.1    # [0-1] std from nominal value\n",
    "        max_false_copies       = 2      # max number of copies inserted to cluster\n",
    "        false_copies_prob      = 0.3\n",
    "        min_cluster_size_for_false_copies = 4\n",
    "    \"\"\"\n",
    "    \n",
    "    # Noise variation - adds Gaussian noise to error rates\n",
    "    # Paper: \"varies the standard deviation of the generated noise statistics\"\n",
    "    generate_data_noise = 0.1  # δ = 0.1 (10% std from nominal)\n",
    "    \n",
    "    # False copies injection - simulates clustering errors\n",
    "    # Paper: \"injects random false copies into the training process\"\n",
    "    max_false_copies = 2\n",
    "    false_copies_prob = 0.3  # 30% probability\n",
    "    min_cluster_size_for_false_copies = 4\n",
    "    \n",
    "    # Cluster size range\n",
    "    min_cluster_size = 1\n",
    "    max_cluster_size = 16\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def num2dna(seq):\n",
    "    \"\"\"Convert numeric sequence to DNA string.\"\"\"\n",
    "    mapping = {0: 'A', 1: 'C', 2: 'G', 3: 'T'}\n",
    "    return ''.join([mapping[i] for i in seq])\n",
    "\n",
    "\n",
    "def inject_false_copies(noisy_copies, config):\n",
    "    \"\"\"\n",
    "    Inject random false copies into a cluster.\n",
    "    \n",
    "    This is a KEY augmentation from the paper that simulates clustering errors\n",
    "    where reads from different sequences get incorrectly assigned to a cluster.\n",
    "    \n",
    "    From the paper (Supplementary):\n",
    "    \"The first mechanism injects random false copies into the training process.\n",
    "    This helps the model learn how to ignore such cases that occur due to\n",
    "    clustering errors.\"\n",
    "    \n",
    "    From data_loader.py get_false_copies():\n",
    "        if np.random.random() < config.false_copies_prob and \n",
    "           len(noisy_copies) > config.min_cluster_size_for_false_copies:\n",
    "            num_false_copies = np.random.randint(1, config.max_false_copies+1)\n",
    "            # Replace random copies with completely random sequences\n",
    "    \"\"\"\n",
    "    # Only inject if cluster is large enough and random check passes\n",
    "    if (np.random.random() < config.false_copies_prob and \n",
    "        len(noisy_copies) > config.min_cluster_size_for_false_copies):\n",
    "        \n",
    "        # Randomly choose how many false copies (1 to max)\n",
    "        num_false_copies = np.random.randint(1, config.max_false_copies + 1)\n",
    "        \n",
    "        # Pick random positions to replace (without replacement)\n",
    "        num_to_replace = min(num_false_copies, len(noisy_copies))\n",
    "        indices_to_replace = np.random.choice(\n",
    "            len(noisy_copies), \n",
    "            size=num_to_replace,\n",
    "            replace=False\n",
    "        )\n",
    "        \n",
    "        # Replace with completely random sequences\n",
    "        for idx in indices_to_replace:\n",
    "            original_length = len(noisy_copies[idx])\n",
    "            # Generate random DNA sequence of same length\n",
    "            random_seq = num2dna(np.random.randint(4, size=(original_length,)))\n",
    "            noisy_copies[idx] = random_seq\n",
    "    \n",
    "    return noisy_copies\n",
    "\n",
    "\n",
    "def create_random_label(length):\n",
    "    \"\"\"Generate a random DNA sequence of given length.\"\"\"\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    return ''.join(random.choices(bases, k=length))\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN GENERATOR FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "def generate_synthetic_dataset(\n",
    "    dataset_name,\n",
    "    num_clusters,\n",
    "    output_dir=\"generated_data_corrected\",\n",
    "    use_false_copies=True,\n",
    "    use_noise_deviation=True,\n",
    "    custom_noise_coef=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic dataset for a specific configuration.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_name : str\n",
    "        One of the keys in DATASET_CONFIGS\n",
    "    num_clusters : int\n",
    "        Number of clusters to generate\n",
    "    output_dir : str\n",
    "        Directory to save generated data\n",
    "    use_false_copies : bool\n",
    "        Whether to inject false copies (recommended: True)\n",
    "    use_noise_deviation : bool\n",
    "        Whether to vary error rates per cluster with delta=0.1 (recommended: True)\n",
    "    custom_noise_coef : dict, optional\n",
    "        Custom multipliers for error rates\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    str : Path to generated file\n",
    "    \"\"\"\n",
    "    # Validate dataset name\n",
    "    if dataset_name not in DATASET_CONFIGS:\n",
    "        available = list(DATASET_CONFIGS.keys())\n",
    "        raise ValueError(f\"Unknown dataset '{dataset_name}'.\\nAvailable: {available}\")\n",
    "    \n",
    "    ds_config = DATASET_CONFIGS[dataset_name]\n",
    "    aug_config = AugmentationConfig()\n",
    "    \n",
    "    # Print configuration\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\"GENERATING: {dataset_name}\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Description: {ds_config['description']}\")\n",
    "    print(f\"\\nDataset Parameters:\")\n",
    "    print(f\"  Label length:     {ds_config['label_length']} bp\")\n",
    "    print(f\"  Max deviation:    {ds_config['max_deviation']} bp\")\n",
    "    print(f\"  Max read length:  {ds_config['label_length'] + ds_config['max_deviation']} bp\")\n",
    "    print(f\"  Index length:     {ds_config['index_length']} bp\")\n",
    "    print(f\"  Sequencing:       {ds_config['sequencing_tech']}\")\n",
    "    print(f\"  Synthesis:        {ds_config['synthesis_tech']}\")\n",
    "    print(f\"  Error rates:      {ds_config['error_rates_method']}()\")\n",
    "    print(f\"\\nAugmentation Settings:\")\n",
    "    print(f\"  Noise deviation (δ): {'0.1 (enabled)' if use_noise_deviation else 'disabled'}\")\n",
    "    print(f\"  False copies:        {'enabled (30% prob, max 2)' if use_false_copies else 'disabled'}\")\n",
    "    print(f\"  Cluster size:        {aug_config.min_cluster_size}-{aug_config.max_cluster_size}\")\n",
    "    \n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    output_filename = f\"binned_synthetic_{dataset_name.lower()}.txt\"\n",
    "    output_path = os.path.join(output_dir, output_filename)\n",
    "    print(f\"\\nOutput: {output_path}\")\n",
    "    print(f\"Clusters to generate: {num_clusters:,}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Initialize error rates\n",
    "    errors_prob = ErrorRates()\n",
    "    \n",
    "    # Call the CORRECT method for this dataset\n",
    "    method_name = ds_config['error_rates_method']\n",
    "    method = getattr(errors_prob, method_name)\n",
    "    \n",
    "    if ds_config.get('uses_noise_coef', False):\n",
    "        # Some methods require noise_coef parameter\n",
    "        noise_coef = custom_noise_coef or ds_config.get('noise_coef', {\n",
    "            'del_mult': 1.0, 'ins_mult': 1.0, 'sub_mult': 1.0\n",
    "        })\n",
    "        method(noise_coef)\n",
    "        print(f\"  Applied noise coefficients: {noise_coef}\")\n",
    "    else:\n",
    "        method()\n",
    "    \n",
    "    label_length = ds_config['label_length']\n",
    "    delta = aug_config.generate_data_noise if use_noise_deviation else 0\n",
    "    separator = \"******************\"\n",
    "    \n",
    "    # Generate data\n",
    "    with open(output_path, 'w') as f:\n",
    "        for _ in tqdm(range(num_clusters), desc=f\"Generating {dataset_name}\"):\n",
    "            # 1. Generate random label sequence\n",
    "            label = create_random_label(label_length)\n",
    "            \n",
    "            # 2. Create cluster generator with correct error rates\n",
    "            generator = ClusterGenerator(\n",
    "                total_error_rates=errors_prob.general_errors,\n",
    "                base_error_rates=errors_prob.per_base_errors,\n",
    "                strand=label,\n",
    "                min_copies=aug_config.min_cluster_size,\n",
    "                max_copies=aug_config.max_cluster_size\n",
    "            )\n",
    "            \n",
    "            # 3. Generate noisy reads with optional noise deviation\n",
    "            # delta > 0 adds Gaussian variation to error rates per cluster\n",
    "            generator.generate_cluster(delta=delta)\n",
    "            reads = list(generator.copies)  # Make a copy\n",
    "            \n",
    "            # 4. KEY: Inject false copies to simulate clustering errors\n",
    "            if use_false_copies:\n",
    "                reads = inject_false_copies(reads, aug_config)\n",
    "            \n",
    "            # 5. Write to binned format\n",
    "            f.write(label + \"\\n\")\n",
    "            f.write(separator + \"\\n\")\n",
    "            for read in reads:\n",
    "                f.write(read + \"\\n\")\n",
    "            f.write(\"\\n\")\n",
    "    \n",
    "    print(f\"\\n✅ Successfully generated {num_clusters:,} clusters for {dataset_name}\")\n",
    "    print(f\"   Saved to: {output_path}\\n\")\n",
    "    \n",
    "    return output_path\n",
    "\n",
    "\n",
    "def generate_all_datasets(\n",
    "    num_clusters_per_dataset=1500000,\n",
    "    output_dir=\"generated_data_corrected\",\n",
    "    datasets_to_generate=None,\n",
    "    use_false_copies=True,\n",
    "    use_noise_deviation=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Generate synthetic data for ALL or selected datasets.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    num_clusters_per_dataset : int\n",
    "        Number of clusters to generate per dataset\n",
    "    output_dir : str\n",
    "        Directory to save generated data\n",
    "    datasets_to_generate : list, optional\n",
    "        List of dataset names to generate. If None, generates all.\n",
    "    use_false_copies : bool\n",
    "        Whether to inject false copies\n",
    "    use_noise_deviation : bool\n",
    "        Whether to vary error rates\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Mapping of dataset names to output file paths\n",
    "    \"\"\"\n",
    "    if datasets_to_generate is None:\n",
    "        datasets_to_generate = list(DATASET_CONFIGS.keys())\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" DNAformer Synthetic Data Generator - ALL CONFIGURATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nWill generate {num_clusters_per_dataset:,} clusters for each of:\")\n",
    "    for name in datasets_to_generate:\n",
    "        print(f\"  - {name}: {DATASET_CONFIGS[name]['description']}\")\n",
    "    print(f\"\\nOutput directory: {output_dir}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    generated_files = {}\n",
    "    \n",
    "    for dataset_name in datasets_to_generate:\n",
    "        try:\n",
    "            output_path = generate_synthetic_dataset(\n",
    "                dataset_name=dataset_name,\n",
    "                num_clusters=num_clusters_per_dataset,\n",
    "                output_dir=output_dir,\n",
    "                use_false_copies=use_false_copies,\n",
    "                use_noise_deviation=use_noise_deviation\n",
    "            )\n",
    "            generated_files[dataset_name] = output_path\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error generating {dataset_name}: {e}\")\n",
    "            generated_files[dataset_name] = None\n",
    "    \n",
    "    # Print summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" GENERATION COMPLETE - SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    for name, path in generated_files.items():\n",
    "        status = \"✅\" if path else \"❌\"\n",
    "        print(f\"  {status} {name}: {path or 'FAILED'}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    return generated_files\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# COMPARISON TABLE\n",
    "# ============================================================================\n",
    "\n",
    "def print_all_configurations():\n",
    "    \"\"\"Print a summary table of all dataset configurations.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\" ALL DATASET CONFIGURATIONS\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"{'Dataset':<25} {'Label':<7} {'Dev':<5} {'Idx':<5} {'Sequencing':<20} {'Synthesis':<20} {'Method'}\")\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    for name, config in DATASET_CONFIGS.items():\n",
    "        print(f\"{name:<25} {config['label_length']:<7} {config['max_deviation']:<5} \"\n",
    "              f\"{config['index_length']:<5} {config['sequencing_tech']:<20} \"\n",
    "              f\"{config['synthesis_tech']:<20} {config['error_rates_method']}\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "# MAIN EXECUTION\n",
    "# ============================================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Print all available configurations\n",
    "    print_all_configurations()\n",
    "    \n",
    "    # ==== CONFIGURATION ====\n",
    "    # Modify these parameters as needed\n",
    "    \n",
    "    NUM_CLUSTERS = 1500000  # Start smaller for testing, use 100k+ for training\n",
    "    OUTPUT_DIR = \"generated_data_corrected\"\n",
    "    \n",
    "    # Choose which datasets to generate:\n",
    "    # Option 1: Generate ALL datasets\n",
    "    # DATASETS = None\n",
    "    \n",
    "    # Option 2: Generate only public benchmarks\n",
    "    DATASETS = [\"Erlich\", \"Grass\", \"Organick\", \"Srinivasavaradhan\"]\n",
    "    \n",
    "    # Option 3: Generate only DNAformer's own datasets\n",
    "    # DATASETS = [\"DNAformer_Illumina_Full\", \"DNAformer_Nanopore_Full\"]\n",
    "    \n",
    "    # Option 4: Generate a single dataset\n",
    "    # DATASETS = [\"Erlich\"]\n",
    "    \n",
    "    # ==== GENERATE ====\n",
    "    \n",
    "    generated = generate_all_datasets(\n",
    "        num_clusters_per_dataset=NUM_CLUSTERS,\n",
    "        output_dir=OUTPUT_DIR,\n",
    "        datasets_to_generate=None,\n",
    "        use_false_copies=True,      # Highly recommended\n",
    "        use_noise_deviation=True,   # Highly recommended\n",
    "    )\n",
    "    \n",
    "    # ==== USAGE SUMMARY ====\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\" NEXT STEPS\")\n",
    "    print(\"=\"*70)\n",
    "    print(\"\"\"\n",
    "To use the generated data for training, update your training config:\n",
    "\n",
    "For Erlich dataset:\n",
    "    TRAIN_FILE = \"generated_data_corrected/binned_synthetic_erlich.txt\"\n",
    "    LABEL_SEQ_LEN = 152\n",
    "    MAX_READ_LEN = 162  # label_length + max_deviation\n",
    "\n",
    "For Grass dataset:\n",
    "    TRAIN_FILE = \"generated_data_corrected/binned_synthetic_grass.txt\"\n",
    "    LABEL_SEQ_LEN = 117\n",
    "    MAX_READ_LEN = 128  # 117 + 11\n",
    "\n",
    "For Organick dataset:\n",
    "    TRAIN_FILE = \"generated_data_corrected/binned_synthetic_organick.txt\"\n",
    "    LABEL_SEQ_LEN = 110\n",
    "    MAX_READ_LEN = 115  # 110 + 5\n",
    "\n",
    "For DNAformer Nanopore:\n",
    "    TRAIN_FILE = \"generated_data_corrected/binned_synthetic_dnaformer_nanopore_full.txt\"\n",
    "    LABEL_SEQ_LEN = 140\n",
    "    MAX_READ_LEN = 144  # 140 + 4\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
